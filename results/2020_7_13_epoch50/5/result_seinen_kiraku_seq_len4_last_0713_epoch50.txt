class weight : tensor([0.7568, 0.1607])
best:lr 7.5447643353466e-07
EPOCH : 1 / 50
VAL_LOSS : 0.679926886008336 
VAL_ACCURACY : 0.2316043425814234
VAL_F1 : 0.37610186061455375

EPOCH : 2 / 50
VAL_LOSS : 0.6713526088457841 
VAL_ACCURACY : 0.2316043425814234
VAL_F1 : 0.37364798396042115

EPOCH : 3 / 50
VAL_LOSS : 0.6617888097579663 
VAL_ACCURACY : 0.33293124246079614
VAL_F1 : 0.3393070486301164

EPOCH : 4 / 50
VAL_LOSS : 0.6485210817593795 
VAL_ACCURACY : 0.3835946924004825
VAL_F1 : 0.35723270403525176

EPOCH : 5 / 50
VAL_LOSS : 0.6352928785177377 
VAL_ACCURACY : 0.47165259348612787
VAL_F1 : 0.3933518001625064

EPOCH : 6 / 50
VAL_LOSS : 0.6225279076741292 
VAL_ACCURACY : 0.5186972255729795
VAL_F1 : 0.4158125911026584

EPOCH : 7 / 50
VAL_LOSS : 0.6045090653575383 
VAL_ACCURACY : 0.5669481302774427
VAL_F1 : 0.4416796263293611

EPOCH : 8 / 50
VAL_LOSS : 0.5846833489262141 
VAL_ACCURACY : 0.632086851628468
VAL_F1 : 0.4821731744315968

EPOCH : 9 / 50
VAL_LOSS : 0.5642913069862586 
VAL_ACCURACY : 0.6598311218335344
VAL_F1 : 0.5017667840022226

EPOCH : 10 / 50
VAL_LOSS : 0.5381116230900471 
VAL_ACCURACY : 0.7189384800965019
VAL_F1 : 0.5578747623430467

EPOCH : 11 / 50
VAL_LOSS : 0.5107070070046645 
VAL_ACCURACY : 0.7768395657418576
VAL_F1 : 0.6379647744794635

EPOCH : 12 / 50
VAL_LOSS : 0.4830467425859891 
VAL_ACCURACY : 0.8287092882991556
VAL_F1 : 0.7066115697663583

EPOCH : 13 / 50
VAL_LOSS : 0.4553896475296754 
VAL_ACCURACY : 0.8685162846803377
VAL_F1 : 0.7604395599483927

EPOCH : 14 / 50
VAL_LOSS : 0.4278118828168282 
VAL_ACCURACY : 0.8817852834740652
VAL_F1 : 0.7802690578021276

EPOCH : 15 / 50
VAL_LOSS : 0.40347012189718395 
VAL_ACCURACY : 0.8854041013268998
VAL_F1 : 0.7902869752255506

EPOCH : 16 / 50
VAL_LOSS : 0.3794856375226608 
VAL_ACCURACY : 0.8890229191797346
VAL_F1 : 0.800865800376586

EPOCH : 17 / 50
VAL_LOSS : 0.36005254691609967 
VAL_ACCURACY : 0.8950542822677925
VAL_F1 : 0.8104575158496875

EPOCH : 18 / 50
VAL_LOSS : 0.3383394138744244 
VAL_ACCURACY : 0.9143546441495778
VAL_F1 : 0.8397291191439039

EPOCH : 19 / 50
VAL_LOSS : 0.31637805327773094 
VAL_ACCURACY : 0.916767189384801
VAL_F1 : 0.844943819730317

EPOCH : 20 / 50
VAL_LOSS : 0.2997254500022301 
VAL_ACCURACY : 0.9179734620024126
VAL_F1 : 0.8482142852207033

EPOCH : 21 / 50
VAL_LOSS : 0.2800593361831628 
VAL_ACCURACY : 0.9191797346200241
VAL_F1 : 0.8507795095289606

EPOCH : 22 / 50
VAL_LOSS : 0.2687522413638922 
VAL_ACCURACY : 0.9203860072376358
VAL_F1 : 0.8526785709349689

EPOCH : 23 / 50
VAL_LOSS : 0.24879416508170274 
VAL_ACCURACY : 0.9203860072376358
VAL_F1 : 0.8533333328402963

EPOCH : 24 / 50
VAL_LOSS : 0.23615979833098558 
VAL_ACCURACY : 0.9215922798552473
VAL_F1 : 0.8552338525133507

EPOCH : 25 / 50
VAL_LOSS : 0.22680263608120954 
VAL_ACCURACY : 0.9227985524728589
VAL_F1 : 0.8571428566492347

EPOCH : 26 / 50
VAL_LOSS : 0.2108055890466158 
VAL_ACCURACY : 0.9227985524728589
VAL_F1 : 0.8571428566492347

EPOCH : 27 / 50
VAL_LOSS : 0.20047755697025701 
VAL_ACCURACY : 0.9227985524728589
VAL_F1 : 0.8571428566492347

EPOCH : 28 / 50
VAL_LOSS : 0.19236968944852167 
VAL_ACCURACY : 0.9227985524728589
VAL_F1 : 0.8571428566492347

EPOCH : 29 / 50
VAL_LOSS : 0.17862311077232546 
VAL_ACCURACY : 0.9227985524728589
VAL_F1 : 0.8571428566492347

EPOCH : 30 / 50
VAL_LOSS : 0.1667048386656321 
VAL_ACCURACY : 0.9227985524728589
VAL_F1 : 0.8571428566492347

EPOCH : 31 / 50
VAL_LOSS : 0.15390361472964287 
VAL_ACCURACY : 0.9276236429433052
VAL_F1 : 0.8648648643700999

EPOCH : 32 / 50
VAL_LOSS : 0.1494697669091133 
VAL_ACCURACY : 0.9312424607961399
VAL_F1 : 0.870748298824132

EPOCH : 33 / 50
VAL_LOSS : 0.13878586866821235 
VAL_ACCURACY : 0.9348612786489746
VAL_F1 : 0.8767123282707201

EPOCH : 34 / 50
VAL_LOSS : 0.1342339262796136 
VAL_ACCURACY : 0.9348612786489746
VAL_F1 : 0.8767123282707201

EPOCH : 35 / 50
VAL_LOSS : 0.12712607317819044 
VAL_ACCURACY : 0.9384800965018094
VAL_F1 : 0.8827586201924693

EPOCH : 36 / 50
VAL_LOSS : 0.11692438081193429 
VAL_ACCURACY : 0.9420989143546441
VAL_F1 : 0.8888888883909465

EPOCH : 37 / 50
VAL_LOSS : 0.1090795652797589 
VAL_ACCURACY : 0.9469240048250904
VAL_F1 : 0.8971962611833347

EPOCH : 38 / 50
VAL_LOSS : 0.10460835193785337 
VAL_ACCURACY : 0.9445114595898673
VAL_F1 : 0.8930232553155218

EPOCH : 39 / 50
VAL_LOSS : 0.09982362353744414 
VAL_ACCURACY : 0.9469240048250904
VAL_F1 : 0.8971962611833347

EPOCH : 40 / 50
VAL_LOSS : 0.09366601741371247 
VAL_ACCURACY : 0.9529553679131484
VAL_F1 : 0.9078014179396744

EPOCH : 41 / 50
VAL_LOSS : 0.08930628757494 
VAL_ACCURACY : 0.9589867310012062
VAL_F1 : 0.9186602865802523

EPOCH : 42 / 50
VAL_LOSS : 0.08326058344055827 
VAL_ACCURACY : 0.9589867310012062
VAL_F1 : 0.9186602865802523

EPOCH : 43 / 50
VAL_LOSS : 0.07637407931570823 
VAL_ACCURACY : 0.9662243667068757
VAL_F1 : 0.9320388344492412

EPOCH : 44 / 50
VAL_LOSS : 0.07504420928083934 
VAL_ACCURACY : 0.9662243667068757
VAL_F1 : 0.9320388344492412

EPOCH : 45 / 50
VAL_LOSS : 0.07085209081952389 
VAL_ACCURACY : 0.9686369119420989
VAL_F1 : 0.9365853653511005

EPOCH : 46 / 50
VAL_LOSS : 0.06142827478022529 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.938875305120749

EPOCH : 47 / 50
VAL_LOSS : 0.0624379925788022 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.938875305120749

EPOCH : 48 / 50
VAL_LOSS : 0.05519084886719401 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.955223880093265

EPOCH : 49 / 50
VAL_LOSS : 0.05300156901089045 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.955223880093265

EPOCH : 50 / 50
VAL_LOSS : 0.05061607687877348 
VAL_ACCURACY : 0.9782870928829915
VAL_F1 : 0.955223880093265

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: 少々マニアックだろうか…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: ありがとうございます… それ 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
# 5話-1
# 文: 小説はあまり読まないのですが研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: ありがとう…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 7話-0
# 文: 別に気にしませんが…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 8話-1
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: ?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
------------------------test acc------------------------
Test Acc : 0.6462
correct: 42, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.344828   0.888889  0.646154   0.616858      0.771706
recall      0.714286   0.627451  0.646154   0.670868      0.646154
f1-score    0.465116   0.735632  0.646154   0.600374      0.677367
support    14.000000  51.000000  0.646154  65.000000     65.000000
正例のF1値 : 0.4651162786089778
class weight : tensor([0.7568, 0.1607])
best:lr 2.8324884546194507e-06
EPOCH : 1 / 50
VAL_LOSS : 0.6384195673924226 
VAL_ACCURACY : 0.4016887816646562
VAL_F1 : 0.41784037523673656

EPOCH : 2 / 50
VAL_LOSS : 0.5676679571087544 
VAL_ACCURACY : 0.6658624849215923
VAL_F1 : 0.5391014970675497

EPOCH : 3 / 50
VAL_LOSS : 0.4621381043241574 
VAL_ACCURACY : 0.8492159227985525
VAL_F1 : 0.733475479257432

EPOCH : 4 / 50
VAL_LOSS : 0.3553792487543363 
VAL_ACCURACY : 0.8890229191797346
VAL_F1 : 0.7973568277022066

EPOCH : 5 / 50
VAL_LOSS : 0.2682869743842345 
VAL_ACCURACY : 0.9095295536791315
VAL_F1 : 0.8344370856006316

EPOCH : 6 / 50
VAL_LOSS : 0.20574723083812457 
VAL_ACCURACY : 0.9131483715319663
VAL_F1 : 0.8421052626666667

EPOCH : 7 / 50
VAL_LOSS : 0.15055833842891914 
VAL_ACCURACY : 0.9348612786489746
VAL_F1 : 0.8767123282707201

EPOCH : 8 / 50
VAL_LOSS : 0.11843945967176786 
VAL_ACCURACY : 0.9493365500603136
VAL_F1 : 0.9014084502048535

EPOCH : 9 / 50
VAL_LOSS : 0.09260548873303029 
VAL_ACCURACY : 0.9601930036188179
VAL_F1 : 0.9208633088512326

EPOCH : 10 / 50
VAL_LOSS : 0.07811478786886884 
VAL_ACCURACY : 0.9662243667068757
VAL_F1 : 0.9320388344492412

EPOCH : 11 / 50
VAL_LOSS : 0.06309908015940052 
VAL_ACCURACY : 0.9698431845597105
VAL_F1 : 0.938875305120749

EPOCH : 12 / 50
VAL_LOSS : 0.04469891859648319 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9672544075561168

EPOCH : 13 / 50
VAL_LOSS : 0.04134966044400174 
VAL_ACCURACY : 0.9843184559710495
VAL_F1 : 0.9672544075561168

EPOCH : 14 / 50
VAL_LOSS : 0.0322956948970946 
VAL_ACCURACY : 0.9903498190591074
VAL_F1 : 0.9795918362299042

EPOCH : 15 / 50
VAL_LOSS : 0.025166701534404777 
VAL_ACCURACY : 0.9927623642943305
VAL_F1 : 0.9846153841104537

EPOCH : 16 / 50
VAL_LOSS : 0.019970696876183726 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9871465290579894

EPOCH : 17 / 50
VAL_LOSS : 0.017358345722851273 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9896907211444361

EPOCH : 18 / 50
VAL_LOSS : 0.014339264741955468 
VAL_ACCURACY : 0.9963811821471653
VAL_F1 : 0.9922480615104061

EPOCH : 19 / 50
VAL_LOSS : 0.012283919777613707 
VAL_ACCURACY : 0.9963811821471653
VAL_F1 : 0.9922480615104061

EPOCH : 20 / 50
VAL_LOSS : 0.008606919481490668 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 21 / 50
VAL_LOSS : 0.013083604836048415 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9896907211444361

EPOCH : 22 / 50
VAL_LOSS : 0.00730008446575644 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 23 / 50
VAL_LOSS : 0.0069505903923597475 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 24 / 50
VAL_LOSS : 0.0066948447761555705 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 25 / 50
VAL_LOSS : 0.007344449364329473 
VAL_ACCURACY : 0.9975874547647768
VAL_F1 : 0.9948186523445999

EPOCH : 26 / 50
VAL_LOSS : 0.0059091460447794255 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 27 / 50
VAL_LOSS : 0.0065246996528003365 
VAL_ACCURACY : 0.9975874547647768
VAL_F1 : 0.9948186523445999

EPOCH : 28 / 50
VAL_LOSS : 0.004359869805809397 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 29 / 50
VAL_LOSS : 0.004987637734022708 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 30 / 50
VAL_LOSS : 0.0031241764372680336 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 31 / 50
VAL_LOSS : 0.003678172204392747 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 32 / 50
VAL_LOSS : 0.002330876921545356 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 33 / 50
VAL_LOSS : 0.004062785868882202 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 34 / 50
VAL_LOSS : 0.0022916742958701574 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 35 / 50
VAL_LOSS : 0.0015876682787515724 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 36 / 50
VAL_LOSS : 0.0014328601335784276 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 37 / 50
VAL_LOSS : 0.0016139994057504316 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 38 / 50
VAL_LOSS : 0.00148275057794168 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 39 / 50
VAL_LOSS : 0.0011597704153525857 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 40 / 50
VAL_LOSS : 0.0016687544647049015 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 41 / 50
VAL_LOSS : 0.0014724881408395818 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 42 / 50
VAL_LOSS : 0.000844887818787426 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 43 / 50
VAL_LOSS : 0.001111247402150184 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 44 / 50
VAL_LOSS : 0.0007619024662954661 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 45 / 50
VAL_LOSS : 0.000802538984806653 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 46 / 50
VAL_LOSS : 0.0006199234345471128 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 47 / 50
VAL_LOSS : 0.0007976035480029308 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 48 / 50
VAL_LOSS : 0.0006226359448471788 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 49 / 50
VAL_LOSS : 0.0005014276522650527 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 50 / 50
VAL_LOSS : 0.0005898186198184983 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: ありがとうございます… それ 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 8話-0
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 8話-1
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
------------------------test acc------------------------
Test Acc : 0.7538
correct: 49, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.437500   0.857143  0.753846   0.647321      0.766758
recall      0.500000   0.823529  0.753846   0.661765      0.753846
f1-score    0.466667   0.840000  0.753846   0.653333      0.759590
support    14.000000  51.000000  0.753846  65.000000     65.000000
正例のF1値 : 0.46666666613777774
class weight : tensor([0.7568, 0.1607])
best:lr 6.4571831984984594e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5280579099288354 
VAL_ACCURACY : 0.8262967430639324
VAL_F1 : 0.7209302320880656

EPOCH : 2 / 50
VAL_LOSS : 0.2891197817829939 
VAL_ACCURACY : 0.9095295536791315
VAL_F1 : 0.835886213951113

EPOCH : 3 / 50
VAL_LOSS : 0.15738534110669905 
VAL_ACCURACY : 0.9276236429433052
VAL_F1 : 0.8642533931698574

EPOCH : 4 / 50
VAL_LOSS : 0.08944478143866245 
VAL_ACCURACY : 0.9613992762364294
VAL_F1 : 0.9230769225754438

EPOCH : 5 / 50
VAL_LOSS : 0.058513430394948676 
VAL_ACCURACY : 0.9734620024125452
VAL_F1 : 0.9458128073785824

EPOCH : 6 / 50
VAL_LOSS : 0.03915884755910016 
VAL_ACCURACY : 0.9867310012062727
VAL_F1 : 0.9721518982296428

EPOCH : 7 / 50
VAL_LOSS : 0.021431600343650922 
VAL_ACCURACY : 0.9939686369119421
VAL_F1 : 0.9871465290579894

EPOCH : 8 / 50
VAL_LOSS : 0.015481441169798087 
VAL_ACCURACY : 0.9963811821471653
VAL_F1 : 0.9922480615104061

EPOCH : 9 / 50
VAL_LOSS : 0.011341327246135244 
VAL_ACCURACY : 0.9963811821471653
VAL_F1 : 0.9922480615104061

EPOCH : 10 / 50
VAL_LOSS : 0.00882370122977031 
VAL_ACCURACY : 0.9975874547647768
VAL_F1 : 0.9948186523445999

EPOCH : 11 / 50
VAL_LOSS : 0.007861950031768244 
VAL_ACCURACY : 0.9963811821471653
VAL_F1 : 0.9922480615104061

EPOCH : 12 / 50
VAL_LOSS : 0.0048260958574246615 
VAL_ACCURACY : 0.9987937273823885
VAL_F1 : 0.9974025968974195

EPOCH : 13 / 50
VAL_LOSS : 0.0033408592213303424 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 14 / 50
VAL_LOSS : 0.012488586554984348 
VAL_ACCURACY : 0.9951749095295537
VAL_F1 : 0.9896907211444361

EPOCH : 15 / 50
VAL_LOSS : 0.0027876811375160916 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 16 / 50
VAL_LOSS : 0.0018684621363018567 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 17 / 50
VAL_LOSS : 0.0017357522648615907 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 18 / 50
VAL_LOSS : 0.0012870253357015406 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 19 / 50
VAL_LOSS : 0.0014626646460293648 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 20 / 50
VAL_LOSS : 0.0010540558455082087 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 21 / 50
VAL_LOSS : 0.0024485875759497643 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 22 / 50
VAL_LOSS : 0.000719014915095893 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 23 / 50
VAL_LOSS : 0.0006011824852276521 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 24 / 50
VAL_LOSS : 0.000729161798237608 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 25 / 50
VAL_LOSS : 0.0005715155907987187 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 26 / 50
VAL_LOSS : 0.0004028081451766551 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 27 / 50
VAL_LOSS : 0.00037249254147844534 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 28 / 50
VAL_LOSS : 0.00036063125606653135 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 29 / 50
VAL_LOSS : 0.0002913914806693076 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 30 / 50
VAL_LOSS : 0.000246664998765202 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 31 / 50
VAL_LOSS : 0.0011680624330228267 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 32 / 50
VAL_LOSS : 0.00027682492551460967 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 33 / 50
VAL_LOSS : 0.00021136208110524772 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 34 / 50
VAL_LOSS : 0.00021627153938215299 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 35 / 50
VAL_LOSS : 0.00019495712359247802 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 36 / 50
VAL_LOSS : 0.0001829514024463536 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 37 / 50
VAL_LOSS : 0.0001683050839066989 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 38 / 50
VAL_LOSS : 0.00014912509127148392 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 39 / 50
VAL_LOSS : 0.0001449981811254894 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 40 / 50
VAL_LOSS : 0.00012389344808000786 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 41 / 50
VAL_LOSS : 0.00012360651873258085 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 42 / 50
VAL_LOSS : 9.861975929827447e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 43 / 50
VAL_LOSS : 9.14958819311533e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 44 / 50
VAL_LOSS : 8.704257960254417e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 45 / 50
VAL_LOSS : 8.090156321626497e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 46 / 50
VAL_LOSS : 9.065191191509187e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 47 / 50
VAL_LOSS : 6.432730637803055e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 48 / 50
VAL_LOSS : 6.4815910193899e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 49 / 50
VAL_LOSS : 6.840451848032759e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

EPOCH : 50 / 50
VAL_LOSS : 5.531735958077032e-05 
VAL_ACCURACY : 1.0
VAL_F1 : 0.9999999994947917

# 5話-0
# 文: 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: ありがとうございます… それ 何読んでるんですか?
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
# 5話-1
# 文: 小説はあまり読まないのですが研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-0
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: ジャーン!パフェを作ってみました〜!
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: こうやっていろんな食べ方をすれば飽きないですね
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 8話-0
# 文: 国際会議でスペインにいるBさんからだ
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 8話-0
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 8話-1
# 文: ここは日本…何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 9話-0
# 文: あれ?スペインからもう戻ってきたのか
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
------------------------test acc------------------------
Test Acc : 0.7231
correct: 47, total: 65
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.388889   0.851064  0.723077   0.619976      0.751518
recall      0.500000   0.784314  0.723077   0.642157      0.723077
f1-score    0.437500   0.816327  0.723077   0.626913      0.734733
support    14.000000  51.000000  0.723077  65.000000     65.000000
正例のF1値 : 0.43749999948046875
