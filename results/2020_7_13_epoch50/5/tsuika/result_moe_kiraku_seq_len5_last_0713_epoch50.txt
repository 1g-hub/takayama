class weight : tensor([0.5610, 0.3913])
best:lr 3.919357428511461e-06
EPOCH : 1 / 50
VAL_LOSS : 0.5653537288308144 
VAL_ACCURACY : 0.8459657701711492
VAL_F1 : 0.7941176465593042

EPOCH : 2 / 50
VAL_LOSS : 0.3661396993467441 
VAL_ACCURACY : 0.8875305623471883
VAL_F1 : 0.8618618613593144

EPOCH : 3 / 50
VAL_LOSS : 0.23386029483607182 
VAL_ACCURACY : 0.9058679706601467
VAL_F1 : 0.88659793764211

EPOCH : 4 / 50
VAL_LOSS : 0.15265543672900933 
VAL_ACCURACY : 0.9584352078239609
VAL_F1 : 0.9504373172822039

EPOCH : 5 / 50
VAL_LOSS : 0.10658104218041095 
VAL_ACCURACY : 0.9596577017114915
VAL_F1 : 0.9519650650001844

EPOCH : 6 / 50
VAL_LOSS : 0.08139673663446537 
VAL_ACCURACY : 0.9621026894865525
VAL_F1 : 0.955007256392163

EPOCH : 7 / 50
VAL_LOSS : 0.05541649199305819 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.9763313604441372

EPOCH : 8 / 50
VAL_LOSS : 0.03722711403567631 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9924585213673031

EPOCH : 9 / 50
VAL_LOSS : 0.030053306147097968 
VAL_ACCURACY : 0.9951100244498777
VAL_F1 : 0.9939759031114821

EPOCH : 10 / 50
VAL_LOSS : 0.02588624337938829 
VAL_ACCURACY : 0.9938875305623472
VAL_F1 : 0.9924812025045621

EPOCH : 11 / 50
VAL_LOSS : 0.018964292105430595 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 12 / 50
VAL_LOSS : 0.021330691197922882 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 13 / 50
VAL_LOSS : 0.016808998484451037 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 14 / 50
VAL_LOSS : 0.011546605880049845 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 15 / 50
VAL_LOSS : 0.012025099975289777 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 16 / 50
VAL_LOSS : 0.009613529107390115 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 17 / 50
VAL_LOSS : 0.010049253753655089 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 18 / 50
VAL_LOSS : 0.008778125345438289 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 19 / 50
VAL_LOSS : 0.00803479915842987 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 20 / 50
VAL_LOSS : 0.007157807777940224 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 21 / 50
VAL_LOSS : 0.0060362648842923455 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 22 / 50
VAL_LOSS : 0.010818773476505438 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 23 / 50
VAL_LOSS : 0.008114311556990007 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 24 / 50
VAL_LOSS : 0.005709183467843104 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 25 / 50
VAL_LOSS : 0.007815896266457947 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 26 / 50
VAL_LOSS : 0.008027968783818114 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 27 / 50
VAL_LOSS : 0.00747282194005003 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 28 / 50
VAL_LOSS : 0.005739898752765909 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 29 / 50
VAL_LOSS : 0.005557021642184386 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 30 / 50
VAL_LOSS : 0.00618223380829127 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 31 / 50
VAL_LOSS : 0.0061663061519189235 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 32 / 50
VAL_LOSS : 0.006433061554511928 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 33 / 50
VAL_LOSS : 0.00605169715653084 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 34 / 50
VAL_LOSS : 0.006867527329562178 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 35 / 50
VAL_LOSS : 0.00736475324314457 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 36 / 50
VAL_LOSS : 0.007058605287476474 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 37 / 50
VAL_LOSS : 0.006912621747687808 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 38 / 50
VAL_LOSS : 0.004776452366023967 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 39 / 50
VAL_LOSS : 0.007038922289561574 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 40 / 50
VAL_LOSS : 0.0070432815255816635 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 41 / 50
VAL_LOSS : 0.006205172182280176 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 42 / 50
VAL_LOSS : 0.01077967152475769 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 43 / 50
VAL_LOSS : 0.007233599121858648 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 44 / 50
VAL_LOSS : 0.00582505480738641 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 45 / 50
VAL_LOSS : 0.004711255325394002 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 46 / 50
VAL_LOSS : 0.00649724022535408 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 47 / 50
VAL_LOSS : 0.006468584031258965 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 48 / 50
VAL_LOSS : 0.00730561751501787 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 49 / 50
VAL_LOSS : 0.006720848982905199 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 50 / 50
VAL_LOSS : 0.006571520394118124 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 5話-0
# 文: 適当に流そう
正解 : 1 , 予測 : 0 / 元クラス : 嫌悪
# 5話-0
# 文: 小説はあまり読まないのですが研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: 今日弁当なんですね
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: ありがとう…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 8話-0
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 8話-1
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : 恐怖
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 9話-0
# 文: Bさん…あれ?
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 9話-0
# 文: ここはよその研究室…!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
------------------------test acc------------------------
Test Acc : 0.5156
correct: 33, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.371429   0.689655  0.515625   0.530542      0.580265
recall      0.590909   0.476190  0.515625   0.533550      0.515625
f1-score    0.456140   0.563380  0.515625   0.509760      0.526517
support    22.000000  42.000000  0.515625  64.000000     64.000000
正例のF1値 : 0.4561403503871961
class weight : tensor([0.5610, 0.3913])
best:lr 1.4983430446786264e-05
EPOCH : 1 / 50
VAL_LOSS : 0.191579670430376 
VAL_ACCURACY : 0.9486552567237164
VAL_F1 : 0.9384164217851585

EPOCH : 2 / 50
VAL_LOSS : 0.052299777332406774 
VAL_ACCURACY : 0.980440097799511
VAL_F1 : 0.9762611270937581

EPOCH : 3 / 50
VAL_LOSS : 0.015302547101432888 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 4 / 50
VAL_LOSS : 0.011372585288392236 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 5 / 50
VAL_LOSS : 0.007010701920640154 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 6 / 50
VAL_LOSS : 0.007276470293268526 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 7 / 50
VAL_LOSS : 0.007605148514043181 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 8 / 50
VAL_LOSS : 0.0030812460239618444 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 9 / 50
VAL_LOSS : 0.0028313673526729243 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 10 / 50
VAL_LOSS : 0.004014289182892893 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 11 / 50
VAL_LOSS : 0.0047366939150099195 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 12 / 50
VAL_LOSS : 0.0027282513765385374 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 13 / 50
VAL_LOSS : 0.004382652635355883 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 14 / 50
VAL_LOSS : 0.01344102097335473 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 15 / 50
VAL_LOSS : 0.007854986734645745 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 16 / 50
VAL_LOSS : 0.006946642726129189 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 17 / 50
VAL_LOSS : 0.006899022302674824 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 18 / 50
VAL_LOSS : 0.005959362645136515 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 19 / 50
VAL_LOSS : 0.004708457562208843 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 20 / 50
VAL_LOSS : 0.0060902921284720765 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 21 / 50
VAL_LOSS : 0.006515052421771263 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 22 / 50
VAL_LOSS : 0.0069556004881493345 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 23 / 50
VAL_LOSS : 0.0067853575857358146 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 24 / 50
VAL_LOSS : 0.006043479982543851 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 25 / 50
VAL_LOSS : 0.0032157743197995634 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 26 / 50
VAL_LOSS : 0.006788446596444304 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 27 / 50
VAL_LOSS : 0.004498941168199403 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 28 / 50
VAL_LOSS : 0.004694774461348481 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 29 / 50
VAL_LOSS : 0.007195618009186196 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 30 / 50
VAL_LOSS : 0.004881035886508191 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 31 / 50
VAL_LOSS : 0.006424896685862573 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 32 / 50
VAL_LOSS : 0.005983857156689527 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 33 / 50
VAL_LOSS : 0.005176069869513902 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 34 / 50
VAL_LOSS : 0.0049274903069195155 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 35 / 50
VAL_LOSS : 0.00651244951663662 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 36 / 50
VAL_LOSS : 0.006056540847671736 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 37 / 50
VAL_LOSS : 0.006151167699552109 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 38 / 50
VAL_LOSS : 0.006206424849857775 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 39 / 50
VAL_LOSS : 0.005673316358857287 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 40 / 50
VAL_LOSS : 0.006164307103605237 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 41 / 50
VAL_LOSS : 0.005433690670577982 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 42 / 50
VAL_LOSS : 0.0061812679851457756 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 43 / 50
VAL_LOSS : 0.004677353535752305 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 44 / 50
VAL_LOSS : 0.0036383090159513532 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 45 / 50
VAL_LOSS : 0.0041732816047696224 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 46 / 50
VAL_LOSS : 0.00426564083148133 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 47 / 50
VAL_LOSS : 0.004694234300647902 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 48 / 50
VAL_LOSS : 0.005661286272138218 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 49 / 50
VAL_LOSS : 0.005314005589910336 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 50 / 50
VAL_LOSS : 0.005087241345887168 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 5話-0
# 文: 小説はあまり読まないのですが研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: そうなんだ〜
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: 小説はあまり読まないのですが 研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: ありがとう…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 7話-0
# 文: チョコは一つしかないし悪いよ〜
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 8話-0
# 文: ここは日本 何も見ていない
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 9話-0
# 文: Bさ…ちょっと!
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 9話-0
# 文: 人違い!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
------------------------test acc------------------------
Test Acc : 0.5938
correct: 38, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.433333   0.735294   0.59375   0.584314      0.631495
recall      0.590909   0.595238   0.59375   0.593074      0.593750
f1-score    0.500000   0.657895   0.59375   0.578947      0.603618
support    22.000000  42.000000   0.59375  64.000000     64.000000
正例のF1値 : 0.49999999949260365
class weight : tensor([0.5610, 0.3913])
best:lr 3.261255939399603e-05
EPOCH : 1 / 50
VAL_LOSS : 0.06937683936065206 
VAL_ACCURACY : 0.969437652811736
VAL_F1 : 0.9635036491328893

EPOCH : 2 / 50
VAL_LOSS : 0.01167580349675308 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 3 / 50
VAL_LOSS : 0.0076812845766723445 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 4 / 50
VAL_LOSS : 0.00943106835396835 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 5 / 50
VAL_LOSS : 0.0072172014686377505 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 6 / 50
VAL_LOSS : 0.010000289840088673 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 7 / 50
VAL_LOSS : 0.006114604214277419 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 8 / 50
VAL_LOSS : 0.007696787827276589 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 9 / 50
VAL_LOSS : 0.009781525346974936 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969788514607387

EPOCH : 10 / 50
VAL_LOSS : 0.008412681558044054 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 11 / 50
VAL_LOSS : 0.0083929460771777 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 12 / 50
VAL_LOSS : 0.00848620307834398 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 13 / 50
VAL_LOSS : 0.008745084184808478 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 14 / 50
VAL_LOSS : 0.008239254955417262 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 15 / 50
VAL_LOSS : 0.005068427606580337 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 16 / 50
VAL_LOSS : 0.009822742826320162 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 17 / 50
VAL_LOSS : 0.009558350276270526 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 18 / 50
VAL_LOSS : 0.010203945594727114 
VAL_ACCURACY : 0.9987775061124694
VAL_F1 : 0.9984871401928953

EPOCH : 19 / 50
VAL_LOSS : 0.010097391137151135 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 20 / 50
VAL_LOSS : 0.012146484325468849 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 21 / 50
VAL_LOSS : 0.011916881461992 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 22 / 50
VAL_LOSS : 0.012726656663674545 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 23 / 50
VAL_LOSS : 0.012594108361921687 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 24 / 50
VAL_LOSS : 0.013271765198501621 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 25 / 50
VAL_LOSS : 0.01220059975620503 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 26 / 50
VAL_LOSS : 0.012498730379486634 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 27 / 50
VAL_LOSS : 0.013803584963739013 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 28 / 50
VAL_LOSS : 0.013911728390234237 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 29 / 50
VAL_LOSS : 0.013975868347468069 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 30 / 50
VAL_LOSS : 0.015469489610618089 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 31 / 50
VAL_LOSS : 0.013124670890953474 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 32 / 50
VAL_LOSS : 0.014123238113317992 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 33 / 50
VAL_LOSS : 0.014495827077116 
VAL_ACCURACY : 0.9963325183374083
VAL_F1 : 0.9954614215847352

EPOCH : 34 / 50
VAL_LOSS : 0.00900945931280498 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 35 / 50
VAL_LOSS : 0.009985890243237568 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 36 / 50
VAL_LOSS : 0.009354040296959564 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 37 / 50
VAL_LOSS : 0.009989994003376523 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 38 / 50
VAL_LOSS : 0.01080120632881377 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 39 / 50
VAL_LOSS : 0.011116300249233073 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 40 / 50
VAL_LOSS : 0.009767483006288994 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 41 / 50
VAL_LOSS : 0.009598912393086651 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 42 / 50
VAL_LOSS : 0.010939598347315145 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 43 / 50
VAL_LOSS : 0.010671844366706514 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 44 / 50
VAL_LOSS : 0.012796841234765348 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 45 / 50
VAL_LOSS : 0.0064324981906622725 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 46 / 50
VAL_LOSS : 0.008226427019119105 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 47 / 50
VAL_LOSS : 0.009371751419861924 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 48 / 50
VAL_LOSS : 0.009987419860382719 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 49 / 50
VAL_LOSS : 0.009426088133437815 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

EPOCH : 50 / 50
VAL_LOSS : 0.00977625283819186 
VAL_ACCURACY : 0.9975550122249389
VAL_F1 : 0.9969696964666759

# 5話-0
# 文: 夏目漱石だよ〜 Aくんはどんな本を読むの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: 今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-0
# 文: Bさん、苦手そうだよな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 5話-0
# 文: 小説はあまり読まないのですが研究で利用している青空文庫の作品なら少々
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-0
# 文: 適当に流したな
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-0
# 文: あと、これも読んだよ
正解 : 1 , 予測 : 0 / 元クラス : 憤怒
# 5話-1
# 文: これ読んだよ
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 5話-1
# 文: そうなんだ〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 5話-1
# 文: 本当に今ハマってる本はこの二冊…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: そうなんだ〜 父の分と2つ作ったの
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: ほとんど冷凍食品詰めただけだよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: 見てもいいですか?
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-0
# 文: どうぞどうぞ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-1
# 文: キャー!
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 6話-1
# 文: ベタだなあ
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 6話-1
# 文: 俺も今日弁当なんでおかず分けますよ
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 6話-1
# 文: ありがとう…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-0
# 文: どれがいいですか?
正解 : 1 , 予測 : 0 / 元クラス : ニュートラル
# 7話-0
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: 器用だ!?
正解 : 1 , 予測 : 0 / 元クラス : 驚愕
# 7話-1
# 文: とか言い出すのかと思った…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 7話-1
# 文: Aくんがいなければ独り占めできたのにな…
正解 : 1 , 予測 : 0 / 元クラス : 悲哀
# 8話-1
# 文: でもわざわざ国際会議から送ってくれたんだよな…
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 8話-1
# 文: もう少し頑張るか
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
# 9話-1
# 文: ただいま〜
正解 : 0 , 予測 : 1 / 元クラス : 喜楽
------------------------test acc------------------------
Test Acc : 0.6094
correct: 39, total: 64
------------------------------------------------
                  喜楽        その他  accuracy  macro avg  weighted avg
precision   0.421053   0.688889  0.609375   0.554971      0.596820
recall      0.363636   0.738095  0.609375   0.550866      0.609375
f1-score    0.390244   0.712644  0.609375   0.551444      0.601819
support    22.000000  42.000000  0.609375  64.000000     64.000000
正例のF1値 : 0.390243901922665
